{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cff7bb8-ddfe-4aec-8ec3-c42ea097bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vesselExtractor import *\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import stackview\n",
    "import napari\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import tifffile\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import skimage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef826896-999d-4c4c-aa76-b63236063858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file: /mnt/5404b8a5-71b7-4464-9a1e-b40cd26fac58/Data_Drive/Wissam/Eye_Surgery/shortclips/Short clips (before and after wash)/2023-02_Phaco+LIO+Hydrus (4)_GD.mp4\n"
     ]
    }
   ],
   "source": [
    "# Create a Tk root window (but keep it hidden)\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "# Open file selection dialog for a single file\n",
    "file = filedialog.askopenfilename(\n",
    "    title=\"Select an MP4 File\",\n",
    "    filetypes=[(\"MP4 files\", \"*.mp4\")],\n",
    "    initialdir=\"../shortclips/Short clips (before and after wash)\"\n",
    ")\n",
    "\n",
    "print(\"Selected file:\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5405c5a3-d1e2-4753-8153-6dadcb55d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mp4_as_mmap(mp4_path, mmap_path=\"video_frames.mmap\", dtype=np.uint8):\n",
    "    \"\"\"\n",
    "    Load an MP4 file as a memory-mapped NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        mp4_path (str): Path to the MP4 file.\n",
    "        mmap_path (str): Path to store the memory-mapped file.\n",
    "        dtype (data-type): Data type for the NumPy array. Default is np.uint8.\n",
    "\n",
    "    Returns:\n",
    "        np.memmap: Memory-mapped NumPy array of video frames.\n",
    "    \"\"\"\n",
    "    # Open the video file using OpenCV\n",
    "    video_capture = cv2.VideoCapture(mp4_path)\n",
    "    if not video_capture.isOpened():\n",
    "        raise ValueError(f\"Cannot open video file: {mp4_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    channels = 3  # Assuming the video is in color (BGR format)\n",
    "\n",
    "    # Prepare a memory-mapped array\n",
    "    mmap_shape = (frame_count, frame_height, frame_width, channels)\n",
    "    mmap_array = np.memmap(mmap_path, dtype=dtype, mode=\"w+\", shape=mmap_shape)\n",
    "\n",
    "    # Read and store frames into the memory-mapped array\n",
    "    for i in range(frame_count):\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Could not read frame {i}.\")\n",
    "            break\n",
    "        mmap_array[i] = frame[..., ::-1]\n",
    "\n",
    "    # Release video capture and flush the memory-mapped file\n",
    "    video_capture.release()\n",
    "    mmap_array.flush()\n",
    "\n",
    "    return mmap_array\n",
    "movie = load_mp4_as_mmap(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6a0148bb-3093-48ad-a687-c8e006802dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5469b0f9dd74a1694c666f6570d61b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=1080, width=1920),)),)), IntSlider(value=258, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169437e734894b4991618df4804a94cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Select Frame', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4f01dd8f9e49d9bf30cf6ff5fef5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_viewer = stackview.slice(movie, continuous_update=True)\n",
    "display(nb_viewer)\n",
    "\n",
    "# Create an Output widget\n",
    "output = widgets.Output()\n",
    "# Create a button widget\n",
    "button = widgets.Button(description=\"Select Frame\")\n",
    "\n",
    "img = 0 \n",
    "idx = 0 \n",
    "def on_button_click(b):\n",
    "    global nb_viewer, movie, img, idx  # Make it refer to the global variable\n",
    "    idx = nb_viewer.children[1].value  # Get slider value\n",
    "    img = movie[idx] \n",
    "    \n",
    "# Attach function to button click event\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the button and output widget\n",
    "display(button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca44854f-3586-4fb7-96c5-c7ce66fb0a5e",
   "metadata": {},
   "source": [
    "### Use the Napari Window to add points to both the Sclera and Pupil point layers. Leave the Napari window open to inspect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070391ba-c96b-4b20-871a-ea29287d0d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Points layer 'Pupil' at 0x7f1e9f94dae0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eyeMasks = napari.Viewer()\n",
    "eyeMasks.add_image(img)\n",
    "pupil, sclera = [], []\n",
    "eyeMasks.add_points(sclera, name='Sclera')\n",
    "eyeMasks.add_points(pupil, name='Pupil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19ddff7f-ce03-42c3-8db9-911cdbd22cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sclera = eyeMasks.layers[1].data\n",
    "sclera = sclera[:, [1, 0]]\n",
    "pupil = eyeMasks.layers[2].data\n",
    "pupil= pupil[:, [1, 0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc830845-d05e-4cd7-9d1a-c2d83e9b1ab0",
   "metadata": {},
   "source": [
    "### Generate masks for pupil and sclera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36708c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/.local/lib/python3.10/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'pupil_mask' at 0x7f1e94f97ee0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_checkpoint = \"sam_vit_l_0b3195.pth\"\n",
    "model_type = \"vit_l\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "predictor.set_image(img)\n",
    "\n",
    "sclera_mask, _, _ = predictor.predict(\n",
    "    point_coords=sclera,\n",
    "    point_labels=[1]*sclera.shape[0],\n",
    "    box=None,\n",
    "    multimask_output=False,\n",
    ")\n",
    "pupil_mask, _, _ = predictor.predict(\n",
    "    point_coords=pupil,\n",
    "    point_labels=[1]*pupil.shape[0],\n",
    "    box=None,\n",
    "    multimask_output=False,\n",
    ")\n",
    "sclera_mask[pupil_mask==1]=0\n",
    "eyeMasks.add_labels(sclera_mask)\n",
    "eyeMasks.add_labels(pupil_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8fe98-29c4-4ab2-8f43-010adb06e4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "982a880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72041c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/5404b8a5-71b7-4464-9a1e-b40cd26fac58/Data_Drive/Wissam/Eye_Surgery/VesselExtractor/vesselExtractor.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from BV_Net128.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"BV_Net128.pth\"  # Path to your saved model file\n",
    "loaded_model = load_model(model_path, device, in_channels=1, classes=1)\n",
    "bloodVessels = sliding_window_inference_2d(loaded_model, img, device, threshold=0.15)\n",
    "bloodVessels[pupil_mask[0,::]==1]=0\n",
    "bloodVessels[sclera_mask[0,::]==0]=0\n",
    "eyeMasks.add_labels(bloodVessels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b9fee-bbba-4563-ba14-5d5b4dbcc80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prtBV = np.sum(bloodVessels) / np.sum(sclera_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe2812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created (if not existing): output/\n"
     ]
    }
   ],
   "source": [
    "# Define output directory\n",
    "output_dir = \"output/\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"Output directory created (if not existing):\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f892af54-5608-4f3b-8b6e-1ccfdecc8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "skelVessles = skimage.morphology.skeletonize(bloodVessels).astype(np.int8)\n",
    "_points = np.where(skelVessles==1)\n",
    "branchPoints = []\n",
    "for coords in zip(_points[0], _points[1]):\n",
    "    skellyWind = skelVessles[coords[0]-1:coords[0]+2, coords[1]-1:coords[1]+2].copy()\n",
    "    if  np.sum(skellyWind) ==4:\n",
    "        if np.sum(skellyWind[1, :])==3 or np.sum(skellyWind[:,1])==3:\n",
    "            if np.sum(skellyWind[0, :])==2 or np.sum(skellyWind[:,0])==2:\n",
    "                continue\n",
    "            if np.sum(skellyWind[2, :])==2 or np.sum(skellyWind[:,2])==2:\n",
    "                continue\n",
    "            #if np.sum(skellyWind[0, :])<2 or np.sum(skellyWind[:,0])<2:\n",
    "\n",
    "            if  np.sum(skellyWind) - 1 >=3:\n",
    "                branchPoints.append(coords)\n",
    "    if np.sum(skellyWind) ==4:\n",
    "        if skellyWind[0,0]+ skellyWind[1,1]+skellyWind[2,2] == 3:\n",
    "            if np.sum(skellyWind[1, :])==1 and np.sum(skellyWind[:,1])==1:\n",
    "                branchPoints.append(coords)\n",
    "\n",
    "        if skellyWind[0,2]+ skellyWind[1,1]+skellyWind[2,0] == 3:\n",
    "            if np.sum(skellyWind[1, :])==1 and np.sum(skellyWind[:,1])==1:\n",
    "                branchPoints.append(coords)\n",
    "        _testWindow = skellyWind.copy()\n",
    "        _testWindow[1,1] = 0\n",
    "        if np.sum(_testWindow[0, :])==1 and np.sum(_testWindow[1, :])==1 and np.sum(_testWindow[2, :])==1:\n",
    "            if np.sum(_testWindow[:, 0])==1 and np.sum(_testWindow[:, 1])==1 and np.sum(_testWindow[:, 2])==1:\n",
    "                branchPoints.append(coords) \n",
    "\n",
    "        if np.sum(_testWindow[0, :])==1 and np.sum(_testWindow[1, :])==1 and np.sum(_testWindow[2, :])==1:\n",
    "            if np.sum(_testWindow[:, 0])==1 and np.sum(_testWindow[:, 1])==1 and np.sum(_testWindow[:, 2])==1:\n",
    "                branchPoints.append(coords)\n",
    "\n",
    "        if (np.sum(_testWindow[0, :])==2 and np.sum(_testWindow[2, :])==1) or (np.sum(_testWindow[0, :])==1 and np.sum(_testWindow[2, :])==2):\n",
    "            if np.sum(_testWindow[:, 0])==1 and np.sum(_testWindow[:, 1])==1 and np.sum(_testWindow[:, 2])==1:\n",
    "    \n",
    "                branchPoints.append(coords)\n",
    "        if (np.sum(_testWindow[:, 0])==2 and np.sum(_testWindow[:, 2])==1) or (np.sum(_testWindow[:, 0])==1 and np.sum(_testWindow[:, 2])==2):\n",
    "            if np.sum(_testWindow[:, 0])==1 and np.sum(_testWindow[:, 1])==1 and np.sum(_testWindow[:, 2])==1:\n",
    "    \n",
    "                branchPoints.append(coords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "69ba9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_redness(img, bloodVessels):\n",
    "    masked_pixels = img[bloodVessels == 1]  # Shape (N, 3), where N is the number of masked pixels\n",
    "    # Compute average color within the masked region\n",
    "    average_color = np.mean(masked_pixels, axis=0)\n",
    "\n",
    "    # Compute redness ratio\n",
    "    total_intensity = np.sum(average_color)\n",
    "    red_ratio = average_color[0] / total_intensity if total_intensity > 0 else 0\n",
    "\n",
    "    # Convert to percentage\n",
    "    red_percentage = red_ratio * 100\n",
    "\n",
    "    return tuple(average_color), red_ratio, red_percentage\n",
    "average_color, red_ratio, red_percentage = quantify_redness(img, bloodVessels)\n",
    "prtBV = np.sum(bloodVessels) / np.sum(sclera_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9689b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"File\" : os.path.basename(file),\n",
    "    \"Frame\" : idx,\n",
    "    \"Area %\" : prtBV,\n",
    "    \"Red Ratio\" : red_ratio,\n",
    "    \"Red %\" : red_percentage,\n",
    "    \"Bifurcations\": len(branchPoints)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "089f74e6-fca2-4255-b2a2-cff67b731641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "631f5354-ab27-4270-b9a2-0a62370223a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = \"results.csv\"\n",
    "\n",
    "# Check if the CSV already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    # Append the new data without writing the header\n",
    "    df.to_csv(csv_filename, mode=\"a\", header=False, index=False)\n",
    "else:\n",
    "    # Write the data to a new file with header\n",
    "    df.to_csv(csv_filename, mode=\"w\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096ac1f-cb53-4b6a-acbe-ccc5bffb5c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
